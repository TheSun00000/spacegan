{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-19T09:06:26.860296Z","iopub.status.busy":"2022-08-19T09:06:26.859247Z","iopub.status.idle":"2022-08-19T09:06:29.000059Z","shell.execute_reply":"2022-08-19T09:06:28.998853Z","shell.execute_reply.started":"2022-08-19T09:06:26.860162Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.nn.utils.spectral_norm as spectral_norm\n","\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","\n","import tqdm\n","import cv2\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-19T09:06:29.003011Z","iopub.status.busy":"2022-08-19T09:06:29.002499Z","iopub.status.idle":"2022-08-19T09:06:31.916266Z","shell.execute_reply":"2022-08-19T09:06:31.914715Z","shell.execute_reply.started":"2022-08-19T09:06:29.002980Z"},"trusted":true},"outputs":[],"source":["!git clone https://github.com/vacancy/Synchronized-BatchNorm-PyTorch\n","!mv Synchronized-BatchNorm-PyTorch/sync_batchnorm .\n","from sync_batchnorm import SynchronizedBatchNorm2d"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-19T09:06:31.920014Z","iopub.status.busy":"2022-08-19T09:06:31.919577Z","iopub.status.idle":"2022-08-19T09:06:31.990810Z","shell.execute_reply":"2022-08-19T09:06:31.989642Z","shell.execute_reply.started":"2022-08-19T09:06:31.919968Z"},"trusted":true},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(device)"]},{"cell_type":"markdown","metadata":{},"source":["# Base model:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-19T09:06:31.995205Z","iopub.status.busy":"2022-08-19T09:06:31.994809Z","iopub.status.idle":"2022-08-19T09:06:32.011187Z","shell.execute_reply":"2022-08-19T09:06:32.010105Z","shell.execute_reply.started":"2022-08-19T09:06:31.995157Z"},"trusted":true},"outputs":[],"source":["from torch.nn import init\n","\n","\n","class BaseNetwork(nn.Module):\n","    def __init__(self):\n","        super(BaseNetwork, self).__init__()\n","\n","    @staticmethod\n","    def modify_commandline_options(parser, is_train):\n","        return parser\n","\n","    def print_network(self):\n","        if isinstance(self, list):\n","            self = self[0]\n","        num_params = 0\n","        for param in self.parameters():\n","            num_params += param.numel()\n","        print('Network [%s] was created. Total number of parameters: %.1f million. '\n","              'To see the architecture, do print(network).'\n","              % (type(self).__name__, num_params / 1000000))\n","\n","    def init_weights(self, init_type='normal', gain=0.02):\n","        def init_func(m):\n","            classname = m.__class__.__name__\n","            if classname.find('BatchNorm2d') != -1:\n","                if hasattr(m, 'weight') and m.weight is not None:\n","                    init.normal_(m.weight.data, 1.0, gain)\n","                if hasattr(m, 'bias') and m.bias is not None:\n","                    init.constant_(m.bias.data, 0.0)\n","            elif hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n","                if init_type == 'normal':\n","                    init.normal_(m.weight.data, 0.0, gain)\n","                elif init_type == 'xavier':\n","                    init.xavier_normal_(m.weight.data, gain=gain)\n","                elif init_type == 'xavier_uniform':\n","                    init.xavier_uniform_(m.weight.data, gain=1.0)\n","                elif init_type == 'kaiming':\n","                    init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n","                elif init_type == 'orthogonal':\n","                    init.orthogonal_(m.weight.data, gain=gain)\n","                elif init_type == 'none':  # uses pytorch's default init method\n","                    m.reset_parameters()\n","                else:\n","                    raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n","                if hasattr(m, 'bias') and m.bias is not None:\n","                    init.constant_(m.bias.data, 0.0)\n","\n","        self.apply(init_func)\n","\n","        # propagate to children\n","        for m in self.children():\n","            if hasattr(m, 'init_weights'):\n","                m.init_weights(init_type, gain)"]},{"cell_type":"markdown","metadata":{},"source":["# Generator:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-19T09:06:32.013958Z","iopub.status.busy":"2022-08-19T09:06:32.012681Z","iopub.status.idle":"2022-08-19T09:06:32.025643Z","shell.execute_reply":"2022-08-19T09:06:32.024571Z","shell.execute_reply.started":"2022-08-19T09:06:32.013918Z"},"trusted":true},"outputs":[],"source":["class SPADE(nn.Module):\n","    def __init__(self, norm_nc, label_nc, ks=3):\n","        super().__init__()\n","\n","        self.param_free_norm = SynchronizedBatchNorm2d(norm_nc, affine=False)\n","\n","        # The dimension of the intermediate embedding space. Yes, hardcoded.\n","        nhidden = 128\n","\n","        pw = ks // 2\n","        self.mlp_shared = nn.Sequential(\n","            nn.Conv2d(label_nc, nhidden, kernel_size=ks, padding=pw),\n","            nn.ReLU()\n","        )\n","        self.mlp_gamma = nn.Conv2d(nhidden, norm_nc, kernel_size=ks, padding=pw)\n","        self.mlp_beta = nn.Conv2d(nhidden, norm_nc, kernel_size=ks, padding=pw)\n","\n","    def forward(self, x, segmap):\n","\n","        # Part 1. generate parameter-free normalized activations\n","        normalized = self.param_free_norm(x)\n","\n","        # Part 2. produce scaling and bias conditioned on semantic map\n","        segmap = F.interpolate(segmap, size=x.size()[2:], mode='nearest')\n","        actv   = self.mlp_shared(segmap)\n","        gamma  = self.mlp_gamma(actv)\n","        beta   = self.mlp_beta(actv)\n","\n","        # apply scale and bias\n","        out = normalized * (1 + gamma) + beta\n","\n","        return out\n","\n","# semantic_nc = 3\n","\n","# spade = SPADE(3, semantic_nc)\n","# seg = torch.rand(1,semantic_nc,256,256)\n","# img = torch.rand(1,3,64,64)\n","\n","# spade(img, seg).shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-19T09:06:32.027965Z","iopub.status.busy":"2022-08-19T09:06:32.027029Z","iopub.status.idle":"2022-08-19T09:06:32.041219Z","shell.execute_reply":"2022-08-19T09:06:32.040069Z","shell.execute_reply.started":"2022-08-19T09:06:32.027929Z"},"trusted":true},"outputs":[],"source":["class SPADEResnetBlock(nn.Module):\n","    def __init__(self, fin, fout):\n","        super().__init__()\n","        # Attributes\n","        self.learned_shortcut = (fin != fout)\n","        fmiddle = min(fin, fout)\n","\n","        semantic_nc = 125\n","\n","        # create conv layers\n","        self.conv_0 = nn.Conv2d(fin, fmiddle, kernel_size=3, padding=1)\n","        self.conv_1 = nn.Conv2d(fmiddle, fout, kernel_size=3, padding=1)\n","        if self.learned_shortcut:\n","            self.conv_s = nn.Conv2d(fin, fout, kernel_size=1, bias=False)\n","\n","        # apply spectral norm if specified\n","        \n","        self.conv_0 = spectral_norm(self.conv_0)\n","        self.conv_1 = spectral_norm(self.conv_1)\n","        if self.learned_shortcut:\n","            self.conv_s = spectral_norm(self.conv_s)\n","\n","        # define normalization layers\n","        self.norm_0 = SPADE(fin, semantic_nc)\n","        self.norm_1 = SPADE(fmiddle, semantic_nc)\n","        if self.learned_shortcut:\n","            self.norm_s = SPADE(fin, semantic_nc)\n","\n","    # note the resnet block with SPADE also takes in |seg|,\n","    # the semantic segmentation map as input\n","    def forward(self, x, seg):\n","        x_s = self.shortcut(x, seg)\n","\n","        dx = self.conv_0(self.actvn(self.norm_0(x,  seg)))\n","        dx = self.conv_1(self.actvn(self.norm_1(dx, seg)))\n","\n","        out = x_s + dx\n","\n","        return out\n","\n","    def shortcut(self, x, seg):\n","        if self.learned_shortcut:\n","            x_s = self.conv_s(self.norm_s(x, seg))\n","        else:\n","            x_s = x\n","        return x_s\n","\n","    def actvn(self, x):\n","        return F.leaky_relu(x, 2e-1)\n","\n","\n","# spaderesnetblock = SPADEResnetBlock(3, 16)\n","\n","# seg = torch.rand(1,3,256,256)\n","# img = torch.rand(1,3,64,64)\n","\n","# spaderesnetblock(img, seg).shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-19T09:06:32.045717Z","iopub.status.busy":"2022-08-19T09:06:32.045377Z","iopub.status.idle":"2022-08-19T09:06:32.064865Z","shell.execute_reply":"2022-08-19T09:06:32.063660Z","shell.execute_reply.started":"2022-08-19T09:06:32.045690Z"},"trusted":true},"outputs":[],"source":["class SPADEGenerator(BaseNetwork):\n","    def __init__(self):\n","        super(SPADEGenerator, self).__init__()\n","        self.num_up_layers = 7\n","        nf = 64\n","        self.nf = nf\n","        self.z_dim = 256\n","\n","        self.sw, self.sh = self.compute_latent_vector_size(self.num_up_layers)\n","\n","        # In case of VAE, we will sample from random z vector\n","        self.fc = nn.Linear(self.z_dim, 16 * nf * self.sw * self.sh)\n","\n","        self.head_0 = SPADEResnetBlock(16 * nf, 16 * nf)\n","\n","        self.G_middle_0 = SPADEResnetBlock(16 * nf, 16 * nf)\n","        self.G_middle_1 = SPADEResnetBlock(16 * nf, 16 * nf)\n","\n","        self.up_0 = SPADEResnetBlock(16 * nf, 8 * nf)\n","        self.up_1 = SPADEResnetBlock(8 * nf, 4 * nf)\n","        self.up_2 = SPADEResnetBlock(4 * nf, 2 * nf)\n","        self.up_3 = SPADEResnetBlock(2 * nf, 1 * nf)\n","        \n","        final_nc = nf\n","        \n","        # MOST MOST MOST MOST MOST MOST MOST MOST MOST MOST MOST\n","        if self.num_up_layers == 7:\n","            self.up_4 = SPADEResnetBlock(1 * nf, nf // 2)\n","            final_nc = nf // 2\n","        \n","\n","\n","        self.conv_img = nn.Conv2d(final_nc, 3, 3, padding=1)\n","\n","        self.up = nn.Upsample(scale_factor=2)\n","\n","    def compute_latent_vector_size(self,num_up_layers ):\n","        sw = 256 // (2**num_up_layers)\n","        sh = round(sw)\n","        return sw, sh\n","\n","    def forward(self, input, z=None):\n","        seg = input\n","\n","        # we sample z from unit normal and reshape the tensor\n","        if z is None:\n","            # z = torch.randn(input.size(0), self.z_dim,\n","            #                 dtype=torch.float32, device=input.get_device())\n","            z = torch.randn(input.size(0), self.z_dim,dtype=torch.float32)\n","            \n","        x = self.fc(z)\n","        x = x.view(-1, 16 * self.nf, self.sh, self.sw)\n","\n","        x = self.head_0(x, seg)\n","\n","        x = self.up(x)\n","        x = self.G_middle_0(x, seg)\n","\n","        if self.num_up_layers > 5:\n","            x = self.up(x)\n","\n","        x = self.G_middle_1(x, seg)\n","\n","        x = self.up(x)\n","        x = self.up_0(x, seg)\n","        x = self.up(x)\n","        x = self.up_1(x, seg)\n","        x = self.up(x)\n","        x = self.up_2(x, seg)\n","        x = self.up(x)\n","        x = self.up_3(x, seg)\n","        \n","        if self.num_up_layers == 7:\n","            x = self.up(x)\n","            x = self.up_4(x, seg)\n","\n","        x = self.conv_img(F.leaky_relu(x, 2e-1))\n","        x = F.tanh(x)\n","\n","        return x\n","\n","# spadegenerator = SPADEGenerator()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-19T09:06:32.067797Z","iopub.status.busy":"2022-08-19T09:06:32.066898Z","iopub.status.idle":"2022-08-19T09:06:32.078853Z","shell.execute_reply":"2022-08-19T09:06:32.077600Z","shell.execute_reply.started":"2022-08-19T09:06:32.067758Z"},"trusted":true},"outputs":[],"source":["# seg = torch.rand(1,3,256,256)\n","# generated = spadegenerator(seg)\n","# plt.imshow(generated[0].detach().permute(1,2,0))"]},{"cell_type":"markdown","metadata":{},"source":["# Encoder:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-19T09:06:32.081308Z","iopub.status.busy":"2022-08-19T09:06:32.080481Z","iopub.status.idle":"2022-08-19T09:06:32.098484Z","shell.execute_reply":"2022-08-19T09:06:32.097063Z","shell.execute_reply.started":"2022-08-19T09:06:32.081270Z"},"trusted":true},"outputs":[],"source":["class ConvEncoder(BaseNetwork):\n","    \"\"\" Same architecture as the image discriminator \"\"\"\n","\n","    def __init__(self,):\n","        super(ConvEncoder, self).__init__()\n","\n","        kw = 3\n","        pw = int(np.ceil((kw - 1.0) / 2))\n","        ndf = 64\n","        # norm_layer = get_nonspade_norm_layer(opt, opt.norm_E)\n","        # norm_layer = nn.InstanceNorm2d\n","        self.conv1 = nn.Conv2d(3, ndf, kw, stride=2, padding=pw)\n","        self.conv2 = nn.Conv2d(ndf * 1, ndf * 2, kw, stride=2, padding=pw)\n","        self.conv3 = nn.Conv2d(ndf * 2, ndf * 4, kw, stride=2, padding=pw)\n","        self.conv4 = nn.Conv2d(ndf * 4, ndf * 8, kw, stride=2, padding=pw)\n","        self.conv5 = nn.Conv2d(ndf * 8, ndf * 8, kw, stride=2, padding=pw)\n","        self.conv6 = nn.Conv2d(ndf * 8, ndf * 8, kw, stride=2, padding=pw)\n","\n","        self.bn1 = nn.InstanceNorm2d(ndf)\n","        self.bn2 = nn.InstanceNorm2d(ndf * 2)\n","        self.bn3 = nn.InstanceNorm2d(ndf * 4)\n","        self.bn4 = nn.InstanceNorm2d(ndf * 8)\n","        self.bn5 = nn.InstanceNorm2d(ndf * 8)\n","        self.bn6 = nn.InstanceNorm2d(ndf * 8)\n","\n","\n","        self.so = s0 = 4\n","        self.fc_mu = nn.Linear(ndf * 8 * s0 * s0, 256)\n","        self.fc_var = nn.Linear(ndf * 8 * s0 * s0, 256)\n","\n","        self.actvn = nn.LeakyReLU(0.2, False)\n","\n","    def forward(self, x):\n","        if x.size(2) != 256 or x.size(3) != 256:\n","            x = F.interpolate(x, size=(256, 256), mode='bilinear')\n","\n","        x = self.bn1(self.conv1(x))\n","        x = self.bn2(self.conv2(self.actvn(x)))\n","        x = self.bn3(self.conv3(self.actvn(x)))\n","        x = self.bn4(self.conv4(self.actvn(x)))\n","        x = self.bn5(self.conv5(self.actvn(x)))\n","        x = self.bn6(self.conv6(self.actvn(x)))\n","        x = self.actvn(x)\n","\n","        x = x.view(x.size(0), -1)\n","\n","        mu = self.fc_mu(x)\n","        logvar = self.fc_var(x)\n","\n","        return mu, logvar\n","\n","# encoder = ConvEncoder()\n","# seg = torch.rand(1,3,256,256)\n","# mu, logvar = encoder(seg)"]},{"cell_type":"markdown","metadata":{},"source":["# Discriminator:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-19T09:06:32.104745Z","iopub.status.busy":"2022-08-19T09:06:32.104054Z","iopub.status.idle":"2022-08-19T09:06:32.116489Z","shell.execute_reply":"2022-08-19T09:06:32.115219Z","shell.execute_reply.started":"2022-08-19T09:06:32.104710Z"},"trusted":true},"outputs":[],"source":["class NLayerDiscriminator(BaseNetwork):\n","\n","    def __init__(self):\n","        super(NLayerDiscriminator, self).__init__()\n","\n","        kw = 4\n","        padw = int(np.ceil((kw - 1.0) / 2))\n","        nf = 64\n","        input_nc = 6\n","\n","        sequence = [[nn.Conv2d(input_nc, nf, kernel_size=kw, stride=2, padding=padw),\n","                     nn.LeakyReLU(0.2, False)]]\n","\n","        for n in range(1, 4):\n","            nf_prev = nf\n","            nf = min(nf * 2, 512)\n","            stride = 1 if n == 4 - 1 else 2\n","            sequence += [[\n","                nn.Conv2d(nf_prev, nf, kernel_size=kw,\n","                                               stride=stride, padding=padw),\n","                nn.InstanceNorm2d(nf, affine=False),\n","                nn.LeakyReLU(0.2, False)\n","            ]]\n","\n","        sequence += [[nn.Conv2d(nf, 1, kernel_size=kw, stride=1, padding=padw)]]\n","\n","        # We divide the layers into groups to extract intermediate layer outputs\n","        for n in range(len(sequence)):\n","            self.add_module('model' + str(n), nn.Sequential(*sequence[n]))\n","\n","        # self.model = nn.Sequential(*sequence[n])\n","\n","    def forward(self, input):\n","        results = [input]\n","        for submodel in self.children():\n","            intermediate_output = submodel(results[-1])\n","            results.append(intermediate_output)\n","\n","        return results[1:]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-19T09:06:32.119299Z","iopub.status.busy":"2022-08-19T09:06:32.118538Z","iopub.status.idle":"2022-08-19T09:06:32.129781Z","shell.execute_reply":"2022-08-19T09:06:32.128519Z","shell.execute_reply.started":"2022-08-19T09:06:32.119259Z"},"trusted":true},"outputs":[],"source":["# discriminator = NLayerDiscriminator()\n","# seg = torch.rand(1,6,256,256)\n","# res = discriminator(seg)"]},{"cell_type":"markdown","metadata":{},"source":["# Loss functions:"]},{"cell_type":"markdown","metadata":{},"source":["# Training:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-19T09:06:32.131862Z","iopub.status.busy":"2022-08-19T09:06:32.131481Z","iopub.status.idle":"2022-08-19T09:06:32.373353Z","shell.execute_reply":"2022-08-19T09:06:32.372138Z","shell.execute_reply.started":"2022-08-19T09:06:32.131826Z"},"trusted":true},"outputs":[],"source":["# VGG architecter, used for the perceptual loss using a pretrained VGG network\n","import torchvision\n","class VGG19(torch.nn.Module):\n","    def __init__(self, requires_grad=False):\n","        super().__init__()\n","        vgg_pretrained_features = torchvision.models.vgg19(pretrained=True).features\n","        self.slice1 = torch.nn.Sequential()\n","        self.slice2 = torch.nn.Sequential()\n","        self.slice3 = torch.nn.Sequential()\n","        self.slice4 = torch.nn.Sequential()\n","        self.slice5 = torch.nn.Sequential()\n","        for x in range(2):\n","            self.slice1.add_module(str(x), vgg_pretrained_features[x])\n","        for x in range(2, 7):\n","            self.slice2.add_module(str(x), vgg_pretrained_features[x])\n","        for x in range(7, 12):\n","            self.slice3.add_module(str(x), vgg_pretrained_features[x])\n","        for x in range(12, 21):\n","            self.slice4.add_module(str(x), vgg_pretrained_features[x])\n","        for x in range(21, 30):\n","            self.slice5.add_module(str(x), vgg_pretrained_features[x])\n","        if not requires_grad:\n","            for param in self.parameters():\n","                param.requires_grad = False\n","\n","    def forward(self, X):\n","        h_relu1 = self.slice1(X)\n","        h_relu2 = self.slice2(h_relu1)\n","        h_relu3 = self.slice3(h_relu2)\n","        h_relu4 = self.slice4(h_relu3)\n","        h_relu5 = self.slice5(h_relu4)\n","        out = [h_relu1, h_relu2, h_relu3, h_relu4, h_relu5]\n","        return out\n","\n","# vgg19model = VGG19()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-19T09:06:32.375330Z","iopub.status.busy":"2022-08-19T09:06:32.374940Z","iopub.status.idle":"2022-08-19T09:06:32.382485Z","shell.execute_reply":"2022-08-19T09:06:32.381156Z","shell.execute_reply.started":"2022-08-19T09:06:32.375283Z"},"trusted":true},"outputs":[],"source":["# /home/thesun/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-19T09:06:32.384971Z","iopub.status.busy":"2022-08-19T09:06:32.384003Z","iopub.status.idle":"2022-08-19T09:06:32.395689Z","shell.execute_reply":"2022-08-19T09:06:32.394681Z","shell.execute_reply.started":"2022-08-19T09:06:32.384932Z"},"trusted":true},"outputs":[],"source":["class VGGLoss(nn.Module):\n","    def __init__(self):\n","        super(VGGLoss, self).__init__()\n","        self.vgg = VGG19().to(device)\n","        self.criterion = nn.L1Loss()\n","        self.weights = [1.0 / 32, 1.0 / 16, 1.0 / 8, 1.0 / 4, 1.0]\n","\n","    def forward(self, x, y):\n","        xy = torch.cat((x, y), dim=0)\n","        xy_vgg = self.vgg(xy)\n","        x_vgg = []\n","        y_vgg = []\n","        for p in xy_vgg:\n","            x_vgg.append(p[:p.size(0) // 2])\n","            y_vgg.append(p[p.size(0) // 2:])\n","\n","        loss = 0\n","        for i in range(len(x_vgg)):\n","            loss += self.weights[i] * self.criterion(x_vgg[i], y_vgg[i].detach())\n","        return loss\n","\n","# criterionVGG = VGGLoss()\n","\n","# loss = criterionVGG(fake_image, real_image)\n","# print(loss)"]},{"cell_type":"markdown","metadata":{},"source":["---"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-19T09:06:32.397854Z","iopub.status.busy":"2022-08-19T09:06:32.397404Z","iopub.status.idle":"2022-08-19T09:06:32.421583Z","shell.execute_reply":"2022-08-19T09:06:32.420700Z","shell.execute_reply.started":"2022-08-19T09:06:32.397818Z"},"trusted":true},"outputs":[],"source":["class SpaceGANModel:\n","    def __init__(\n","        self, \n","        encoder,\n","        spadegenerator,\n","        discriminator,\n","        use_vggloss=True,\n","    ):\n","        self.use_vggloss = use_vggloss\n","        self.lambda_kld = 0.1\n","        self.lambda_feat = 10\n","        self.lambda_vgg = 10\n","\n","        self.encoder = encoder.to(device)\n","        self.generator = spadegenerator.to(device)\n","        self.discriminator = discriminator.to(device)\n","        \n","        self.featcriterion = torch.nn.L1Loss()\n","        self.VGGCriterion = VGGLoss()\n","#         self.VGGCriterion = torch.nn.MSELoss()\n","\n","\n","\n","    def reparameterize(self, mu, logvar):\n","        std = torch.exp(0.5 * logvar)\n","        eps = torch.randn_like(std)\n","        return eps.mul(std) + mu\n","\n","    def KLDlossfunction(self, mu, logvar):\n","        return -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) \n","\n","    def criterionGAN(self, x, target_is_real, for_discriminator=True):    \n","        zero_input_tensor = torch.zeros_like(x, requires_grad=False).to(device)\n","        if for_discriminator:\n","            if target_is_real:\n","                minval = torch.min(x - 1, zero_input_tensor)\n","                loss = -torch.mean(minval)\n","            else:\n","                minval = torch.min(-x - 1, zero_input_tensor)\n","                loss = -torch.mean(minval)\n","        else:\n","            assert target_is_real, \"The generator's hinge loss must be aiming for real\"\n","            loss = -torch.mean(x)\n","\n","        return loss\n","\n","\n","\n","    def FeatCriterion(self, pred_fake, pred_real ):\n","        loss = 0\n","        for i in range(len(pred_fake)-1):\n","            loss += self.featcriterion(pred_fake[i], pred_real[i].detach())\n","\n","        return loss \n","\n","\n","\n","    def discriminate(self, input_semantics, fake_image, real_image):\n","\n","        fake_concat = torch.cat([input_semantics, fake_image], dim=1)\n","        real_concat = torch.cat([input_semantics, real_image], dim=1)\n","\n","        fake_and_real = torch.cat([fake_concat, real_concat], dim=0)\n","\n","        discriminator_out = self.discriminator(fake_and_real)\n","\n","        pred_fake = []\n","        pred_real = []\n","\n","        for p in discriminator_out:\n","            pred_fake.append(p[:p.size(0) // 2])\n","            pred_real.append(p[p.size(0) // 2:])\n","\n","        return pred_fake, pred_real\n","\n","\n","    def generator_training_step(self, segmentation, input_semantics, real_image):\n","        \n","        G_losses_dict = {}\n","\n","        mu, logvar = self.encoder(real_image)\n","        z = self.reparameterize(mu, logvar)\n","\n","        KLD_loss = self.KLDlossfunction(mu, logvar) * self.lambda_kld\n","        G_losses_dict['KLD_loss'] = KLD_loss\n","\n","        fake_image = self.generator(input_semantics, z=z)\n","\n","        pred_fake, pred_real = self.discriminate(\n","            segmentation,\n","            fake_image, \n","            real_image\n","        )\n","\n","        GAN_loss = self.criterionGAN(\n","            pred_fake[-1], True,\n","            for_discriminator=False\n","        )\n","        G_losses_dict['GAN_loss'] = GAN_loss\n","\n","\n","        FEAT_loss = self.FeatCriterion(pred_fake, pred_real)\n","        G_losses_dict['FEAT_loss'] = FEAT_loss * self.lambda_feat\n","\n","\n","        if self.use_vggloss:\n","            VGG_loss = self.VGGCriterion(fake_image, real_image)\n","            G_losses_dict['VGG_loss'] = VGG_loss * self.lambda_vgg\n","\n","        \n","        return G_losses_dict, fake_image\n","\n","\n","    def discriminator_training_step(self, segmentation, input_semantics, real_image):\n","        D_losses = {}\n","        with torch.no_grad():\n","            mu, logvar = self.encoder(real_image)\n","            z = self.reparameterize(mu, logvar)\n","            fake_image = self.generator(input_semantics, z=z)\n","            fake_image = fake_image.detach()\n","            fake_image.requires_grad_()\n","            \n","\n","        pred_fake, pred_real = self.discriminate(\n","            segmentation,\n","            fake_image,\n","            real_image\n","        )\n","\n","        D_losses['D_Fake'] = self.criterionGAN(pred_fake[-1], False,\n","                                               for_discriminator=True)\n","        D_losses['D_real'] = self.criterionGAN(pred_real[-1], True,\n","                                               for_discriminator=True)\n","\n","        return D_losses"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-19T09:06:32.424051Z","iopub.status.busy":"2022-08-19T09:06:32.423240Z","iopub.status.idle":"2022-08-19T09:06:32.434660Z","shell.execute_reply":"2022-08-19T09:06:32.433785Z","shell.execute_reply.started":"2022-08-19T09:06:32.423983Z"},"trusted":true},"outputs":[],"source":["# train_master = SpaceGANModel(\n","#     encoder=encoder,\n","#     spadegenerator=spadegenerator,\n","#     discriminator=discriminator\n","# )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-19T09:06:32.438156Z","iopub.status.busy":"2022-08-19T09:06:32.437831Z","iopub.status.idle":"2022-08-19T09:06:32.446195Z","shell.execute_reply":"2022-08-19T09:06:32.445035Z","shell.execute_reply.started":"2022-08-19T09:06:32.438113Z"},"trusted":true},"outputs":[],"source":["# G_losses_dict, fake_image = train_master.generator_training_step(\n","#     input_semantics=torch.rand(1,3,256,256),\n","#     real_image=torch.rand(1,3,256,256)\n","# )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-19T09:06:32.448465Z","iopub.status.busy":"2022-08-19T09:06:32.447920Z","iopub.status.idle":"2022-08-19T09:06:32.456624Z","shell.execute_reply":"2022-08-19T09:06:32.455380Z","shell.execute_reply.started":"2022-08-19T09:06:32.448427Z"},"trusted":true},"outputs":[],"source":["# D_losses_dict = train_master.discriminator_training_step(\n","#     input_semantics=torch.rand(1,3,256,256),\n","#     real_image=torch.rand(1,3,256,256)\n","# )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-19T09:06:32.459576Z","iopub.status.busy":"2022-08-19T09:06:32.458514Z","iopub.status.idle":"2022-08-19T09:06:32.474236Z","shell.execute_reply":"2022-08-19T09:06:32.473216Z","shell.execute_reply.started":"2022-08-19T09:06:32.459539Z"},"trusted":true},"outputs":[],"source":["class SpaceGANModelTrainer:\n","    def __init__(\n","        self, \n","        SpaceGanModel\n","    ):\n","        self.SpaceGanModel = SpaceGanModel\n","        \n","        \n","        self.g_losses = []\n","        self.d_losses = []\n","        self.last_g_losses = None\n","        self.last_d_losses = None\n","        self.last_mask = None\n","        \n","        optimizer_G, optimizer_D = self.create_optimizers()\n","        self.optimizer_G, self.optimizer_D = optimizer_G, optimizer_D\n","        \n","    \n","    def create_optimizers(self):\n","        G_params = list(self.SpaceGanModel.generator.parameters()) + list(self.SpaceGanModel.encoder.parameters())\n","        D_params = list(self.SpaceGanModel.discriminator.parameters())\n","\n","        beta1, beta2 = 0.0, 0.9\n","\n","        G_lr, D_lr = 0.0001, 0.0004\n","\n","        optimizer_G = torch.optim.Adam(G_params, lr=G_lr, betas=(beta1, beta2))\n","        optimizer_D = torch.optim.Adam(D_params, lr=D_lr, betas=(beta1, beta2))\n","\n","        return optimizer_G, optimizer_D\n","        \n","\n","    def run_generator_one_step(self, segmentation, input_semantics, real_image):\n","        self.optimizer_G.zero_grad()\n","        g_losses, generated = self.SpaceGanModel.generator_training_step(segmentation, input_semantics, real_image)\n","        g_loss = sum(g_losses.values()).mean()\n","        g_loss.backward()\n","        self.optimizer_G.step()\n","        g_losses = dict( (k, v.item()) for k, v in g_losses.items())\n","        self.g_losses  += [g_losses]\n","        self.last_g_losses  = g_losses\n","        self.last_generated = generated.detach().cpu()\n","        self.last_mask = input_semantics.detach().cpu()\n","\n","\n","    def run_discriminator_one_step(self, segmentation, input_semantics, real_image):\n","        self.optimizer_D.zero_grad()\n","        d_losses = self.SpaceGanModel.discriminator_training_step(segmentation, input_semantics, real_image)\n","        d_loss = sum(d_losses.values()).mean()\n","        d_loss.backward()\n","        self.optimizer_D.step()\n","        d_losses = dict( (k, v.item()) for k, v in d_losses.items())\n","        self.last_d_losses = d_losses\n","        self.d_losses += [d_losses]\n","        \n","    "]},{"cell_type":"markdown","metadata":{},"source":["# Data:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-19T09:06:32.479088Z","iopub.status.busy":"2022-08-19T09:06:32.477534Z","iopub.status.idle":"2022-08-19T09:06:32.488344Z","shell.execute_reply":"2022-08-19T09:06:32.487353Z","shell.execute_reply.started":"2022-08-19T09:06:32.479061Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import DataLoader,Dataset\n","from torchvision import transforms as T\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-19T09:06:32.490245Z","iopub.status.busy":"2022-08-19T09:06:32.489762Z","iopub.status.idle":"2022-08-19T09:06:32.499206Z","shell.execute_reply":"2022-08-19T09:06:32.498224Z","shell.execute_reply.started":"2022-08-19T09:06:32.490205Z"},"trusted":true},"outputs":[],"source":["COLOR_JITTER = T.ColorJitter(0.5, 0.5, 0.5, 0.4)\n","color_transform = T.RandomChoice([\n","    T.RandomApply([COLOR_JITTER], p=0.6)\n","])\n","\n","primary_transform = T.Compose([\n","    T.RandomHorizontalFlip(),\n","    T.RandomVerticalFlip(),\n","    # T.CenterCrop(size=256),\n","    T.RandomResizedCrop(size=256, ratio=(1, 1), scale=(0.08, 1)),\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-19T09:06:32.501346Z","iopub.status.busy":"2022-08-19T09:06:32.500844Z","iopub.status.idle":"2022-08-19T09:06:32.512699Z","shell.execute_reply":"2022-08-19T09:06:32.511574Z","shell.execute_reply.started":"2022-08-19T09:06:32.501300Z"},"trusted":true},"outputs":[],"source":["def get_segmentation(img, K, blur_kernel=(50,50)):\n","    blured = cv2.blur(img, blur_kernel)\n","    twoDimage = blured.reshape((-1,3))\n","    twoDimage = np.float32(twoDimage)\n","\n","    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n","    attempts=3\n","    ret,label,center=cv2.kmeans(twoDimage,K,None,criteria,attempts,cv2.KMEANS_PP_CENTERS)\n","    center = np.uint8(center)\n","    res = center[label.flatten()]\n","    result_image = res.reshape((img.shape))\n","    return result_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-19T09:08:07.022033Z","iopub.status.busy":"2022-08-19T09:08:07.020711Z","iopub.status.idle":"2022-08-19T09:08:07.036825Z","shell.execute_reply":"2022-08-19T09:08:07.035521Z","shell.execute_reply.started":"2022-08-19T09:08:07.021965Z"},"trusted":true},"outputs":[],"source":["class SpaceImageSegDataset(Dataset):\n","    def __init__(self, path):\n","        super(SpaceImageSegDataset, self).__init__()\n","        images = sorted(os.listdir(path))\n","        loaded_images = []\n","        for img_path in tqdm.tqdm(images):\n","            img = plt.imread(path + '/' + img_path)\n","            if img.shape[0] > 400 and img.shape[1] > 400:\n","                loaded_images.append(img)\n","                \n","        self.images = loaded_images\n","        self.path = path\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        img = self.images[idx]\n","\n","        img = torch.tensor(img)\n","        img = img.permute(2,0,1)\n","        \n","        img = primary_transform(img)\n","        img = color_transform(img).permute(1,2,0)\n","        \n","        seg = get_segmentation(np.array(img), 7, blur_kernel=(20,20))\n","        seg = torch.tensor(seg)\n","\n","        N = 5\n","        seg = torch.floor(torch.floor((seg*(N/256)))*(255/N)).int()\n","        qnt = ((seg[...,0] + seg[...,1] * N + seg[...,2] * N * N) * N // 255).long()\n","#         print(qnt.unique())\n","        sem = torch.nn.functional.one_hot(qnt, N**3).permute(2,0,1)\n","        sem = sem.float()\n","        \n","        img = img.permute(2,0,1) / 127.5 - 1\n","        seg = seg.permute(2,0,1) / 127.5 - 1\n","\n","        # plt.imshow(img.permute(1,2,0))\n","        # plt.show()\n","        # plt.imshow(seg.permute(1,2,0))\n","\n","        return seg.unsqueeze(0), sem.unsqueeze(0) ,img.unsqueeze(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-19T09:06:32.531821Z","iopub.status.busy":"2022-08-19T09:06:32.530669Z","iopub.status.idle":"2022-08-19T09:06:32.544832Z","shell.execute_reply":"2022-08-19T09:06:32.543750Z","shell.execute_reply.started":"2022-08-19T09:06:32.531773Z"},"trusted":true},"outputs":[],"source":["def collate_fn(batch):\n","    segs, sems, imgs = [], [], []\n","    for seg, sem, img in batch:\n","        segs += [seg]\n","        sems += [sem]\n","        imgs += [img]\n","    \n","    segs = torch.cat(segs, dim=0)\n","    sems = torch.cat(sems, dim=0)\n","    imgs = torch.cat(imgs, dim=0)\n","    \n","    return segs, sems, imgs"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-19T09:08:08.640896Z","iopub.status.busy":"2022-08-19T09:08:08.640482Z","iopub.status.idle":"2022-08-19T09:08:27.608919Z","shell.execute_reply":"2022-08-19T09:08:27.607108Z","shell.execute_reply.started":"2022-08-19T09:08:08.640863Z"},"trusted":true},"outputs":[],"source":["dataset = SpaceImageSegDataset('../input/spacegan/clean_images/clean_images')\n","\n","dataloader = DataLoader(\n","    dataset=dataset,\n","    batch_size=1,\n","    shuffle=True, \n","    collate_fn=collate_fn, \n","    prefetch_factor=2, \n","    num_workers=2\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-19T09:08:27.611639Z","iopub.status.busy":"2022-08-19T09:08:27.611149Z","iopub.status.idle":"2022-08-19T09:08:27.618518Z","shell.execute_reply":"2022-08-19T09:08:27.616432Z","shell.execute_reply.started":"2022-08-19T09:08:27.611595Z"},"trusted":true},"outputs":[],"source":["print(len(dataset))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-19T09:08:55.335409Z","iopub.status.busy":"2022-08-19T09:08:55.334976Z","iopub.status.idle":"2022-08-19T09:08:55.340499Z","shell.execute_reply":"2022-08-19T09:08:55.339039Z","shell.execute_reply.started":"2022-08-19T09:08:55.335371Z"},"trusted":true},"outputs":[],"source":["# for i in range(125):\n","#     plt.title(i)\n","#     plt.imshow(sem[0][i].cpu(), cmap='gray')\n","#     plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Start training baby:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-19T09:08:57.266320Z","iopub.status.busy":"2022-08-19T09:08:57.265613Z","iopub.status.idle":"2022-08-19T09:09:28.488907Z","shell.execute_reply":"2022-08-19T09:09:28.487747Z","shell.execute_reply.started":"2022-08-19T09:08:57.266266Z"},"trusted":true},"outputs":[],"source":["GANModel = SpaceGANModel(\n","    encoder=ConvEncoder(),\n","    spadegenerator=SPADEGenerator(),\n","    discriminator=NLayerDiscriminator(),\n","    use_vggloss=True \n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-19T09:16:09.229410Z","iopub.status.busy":"2022-08-19T09:16:09.228979Z","iopub.status.idle":"2022-08-19T09:16:09.236608Z","shell.execute_reply":"2022-08-19T09:16:09.235144Z","shell.execute_reply.started":"2022-08-19T09:16:09.229375Z"},"trusted":true},"outputs":[],"source":["trainer_master = SpaceGANModelTrainer(\n","    GANModel\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-19T09:09:37.166644Z","iopub.status.busy":"2022-08-19T09:09:37.166227Z","iopub.status.idle":"2022-08-19T09:09:48.575553Z","shell.execute_reply":"2022-08-19T09:09:48.574309Z","shell.execute_reply.started":"2022-08-19T09:09:37.166614Z"},"trusted":true},"outputs":[],"source":["old_chkpt = torch.load('../input/spacegan-cnt/spacegan4.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-19T09:16:39.157726Z","iopub.status.busy":"2022-08-19T09:16:39.157150Z","iopub.status.idle":"2022-08-19T09:16:39.351547Z","shell.execute_reply":"2022-08-19T09:16:39.350311Z","shell.execute_reply.started":"2022-08-19T09:16:39.157669Z"},"trusted":true},"outputs":[],"source":["trainer_master.SpaceGanModel.encoder.load_state_dict(old_chkpt['encoder4.pt'])\n","trainer_master.SpaceGanModel.generator.load_state_dict(old_chkpt['generator4.pt'])\n","trainer_master.SpaceGanModel.discriminator.load_state_dict(old_chkpt['discriminator4.pt'])\n","trainer_master.optimizer_D.load_state_dict(old_chkpt['optimizer_D4.pt'])\n","trainer_master.optimizer_G.load_state_dict(old_chkpt['optimizer_G4.pt'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-19T09:16:44.884336Z","iopub.status.busy":"2022-08-19T09:16:44.883937Z","iopub.status.idle":"2022-08-19T09:16:44.894199Z","shell.execute_reply":"2022-08-19T09:16:44.893065Z","shell.execute_reply.started":"2022-08-19T09:16:44.884302Z"},"trusted":true},"outputs":[],"source":["def moving_average(L, ss=200):\n","    s = len(L) // 2\n","    if s == 0:\n","        s = 1\n","    res = []\n","    for i in range(len(L)-s):\n","        res.append(np.mean(L[i:i+s]))\n","    return res\n","\n","def plot_losses(all_losses, ss=200):\n","    keys = all_losses[0].keys()\n","    clean_losses = {}\n","    for k in keys:\n","        clean_losses[k] = moving_average(list(l[k] for l in all_losses), ss)\n","\n","    if len(keys) == 4:\n","        fig, axs = plt.subplots(1, 4 ,figsize=(10, 3))\n","    else:\n","        fig, axs = plt.subplots(1, len(keys) ,figsize=(10, 5))\n","        \n","\n","    for i, k in enumerate(keys):\n","        axs[i].plot(clean_losses[k])\n","        axs[i].set_title(k)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-19T09:16:47.445742Z","iopub.status.busy":"2022-08-19T09:16:47.445025Z","iopub.status.idle":"2022-08-19T09:16:47.570249Z","shell.execute_reply":"2022-08-19T09:16:47.568611Z","shell.execute_reply.started":"2022-08-19T09:16:47.445703Z"},"trusted":true},"outputs":[],"source":["plot_losses(trainer_master.d_losses, ss=5000)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-19T09:17:09.359729Z","iopub.status.busy":"2022-08-19T09:17:09.359326Z","iopub.status.idle":"2022-08-19T12:49:58.204748Z","shell.execute_reply":"2022-08-19T12:49:58.202899Z","shell.execute_reply.started":"2022-08-19T09:17:09.359694Z"},"trusted":true},"outputs":[],"source":["EPOCHS = 300\n","plot_per = 500\n","generator_per = 1\n","\n","\n","\n","for epoch in range(200, EPOCHS+1):\n","    \n","    i = 0\n","    \n","    for sample in tqdm.tqdm(dataloader):\n","        \n","        segmentation_image, input_semantics, real_image = sample\n","        segmentation_image = segmentation_image.to(device)\n","        input_semantics = input_semantics.to(device)\n","        real_image = real_image.to(device)\n","        \n","        if i % 1 == 0:\n","            trainer_master.run_generator_one_step(segmentation_image, input_semantics, real_image)\n","            \n","        if i % 1 == 0:   \n","            trainer_master.run_discriminator_one_step(segmentation_image, input_semantics, real_image)\n","        \n","        i += 1\n","        \n","        \n","    if 0 % plot_per == 0:\n","        fig, axs = plt.subplots(1, 3 ,figsize=(15, 15))\n","        axs[0].imshow(((trainer_master.last_generated[0].permute(1,2,0).detach().cpu() + 1) /2 ))\n","        axs[0].set_title(f'Generated epoch:{epoch}')\n","        axs[1].imshow(((segmentation_image[0].permute(1,2,0).detach().cpu() + 1) /2 ))\n","        axs[1].set_title(f'Segmentation epoch:{epoch}')\n","        axs[2].imshow(((real_image[0].permute(1,2,0).detach().cpu() + 1) /2 ))\n","        axs[2].set_title(f'Real Image epoch:{epoch}')\n","        plt.show()\n","    \n","    if epoch % 10 == 0:  \n","        plot_losses(trainer_master.d_losses, 500)\n","        plot_losses(trainer_master.g_losses, 500)\n","    \n","    \n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-17T21:05:09.361288Z","iopub.status.busy":"2022-08-17T21:05:09.360579Z","iopub.status.idle":"2022-08-17T21:05:09.375762Z","shell.execute_reply":"2022-08-17T21:05:09.374308Z","shell.execute_reply.started":"2022-08-17T21:05:09.361246Z"},"trusted":true},"outputs":[],"source":["for p in trainer_master.SpaceGanModel.encoder.parameters():\n","    print(p.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-19T12:51:36.892491Z","iopub.status.busy":"2022-08-19T12:51:36.892095Z","iopub.status.idle":"2022-08-19T12:51:40.185973Z","shell.execute_reply":"2022-08-19T12:51:40.184732Z","shell.execute_reply.started":"2022-08-19T12:51:36.892455Z"},"trusted":true},"outputs":[],"source":["n = 5\n","torch.save(trainer_master.SpaceGanModel.encoder.state_dict(), f'encoder{n}.pt')\n","torch.save(trainer_master.SpaceGanModel.generator.state_dict(), f'generator{n}.pt')\n","torch.save(trainer_master.SpaceGanModel.discriminator.state_dict(), f'discriminator{n}.pt')\n","torch.save(trainer_master.optimizer_D.state_dict(), f'optimizer_D{n}.pt')\n","torch.save(trainer_master.optimizer_G.state_dict(), f'optimizer_G{n}.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-17T23:04:21.946269Z","iopub.status.busy":"2022-08-17T23:04:21.945216Z","iopub.status.idle":"2022-08-17T23:04:22.133230Z","shell.execute_reply":"2022-08-17T23:04:22.132307Z","shell.execute_reply.started":"2022-08-17T23:04:21.946219Z"},"trusted":true},"outputs":[],"source":["trainer_master.optimizer_D.state_dict()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-17T21:01:13.505378Z","iopub.status.busy":"2022-08-17T21:01:13.504865Z","iopub.status.idle":"2022-08-17T21:01:13.976080Z","shell.execute_reply":"2022-08-17T21:01:13.975083Z","shell.execute_reply.started":"2022-08-17T21:01:13.505327Z"},"trusted":true},"outputs":[],"source":["fig, axs = plt.subplots(1, 3 ,figsize=(15, 15))\n","axs[0].imshow(((trainer_master.last_generated[0].permute(1,2,0).detach().cpu() + 1) /2 ))\n","axs[0].set_title('Generated')\n","axs[1].imshow(((segmentation_image[0].permute(1,2,0).detach().cpu() + 1) /2 ))\n","axs[1].set_title('Segmentation')\n","axs[2].imshow(((real_image[0].permute(1,2,0).detach().cpu() + 1) /2 ))\n","axs[2].set_title('Real Image')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-17T21:01:42.121064Z","iopub.status.busy":"2022-08-17T21:01:42.119985Z","iopub.status.idle":"2022-08-17T21:01:42.186320Z","shell.execute_reply":"2022-08-17T21:01:42.184779Z","shell.execute_reply.started":"2022-08-17T21:01:42.120955Z"},"trusted":true},"outputs":[],"source":["for i in range(125):\n","    plt.title(i)\n","    plt.imshow(input_semantics[0][i].cpu(), cmap='gray')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-17T21:01:51.683880Z","iopub.status.busy":"2022-08-17T21:01:51.683501Z","iopub.status.idle":"2022-08-17T21:01:51.699481Z","shell.execute_reply":"2022-08-17T21:01:51.697843Z","shell.execute_reply.started":"2022-08-17T21:01:51.683849Z"},"trusted":true},"outputs":[],"source":["input_semantics[0][2][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-17T21:01:55.606028Z","iopub.status.busy":"2022-08-17T21:01:55.604978Z","iopub.status.idle":"2022-08-17T21:01:55.621021Z","shell.execute_reply":"2022-08-17T21:01:55.619764Z","shell.execute_reply.started":"2022-08-17T21:01:55.605989Z"},"trusted":true},"outputs":[],"source":["plt"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-08-17T14:49:23.312590Z","iopub.status.idle":"2022-08-17T14:49:23.313331Z","shell.execute_reply":"2022-08-17T14:49:23.313107Z","shell.execute_reply.started":"2022-08-17T14:49:23.313075Z"},"trusted":true},"outputs":[],"source":["class SpaceImageSegDataset(Dataset):\n","    def __init__(self, path):\n","        super(SpaceImageSegDataset, self).__init__()\n","        self.images = sorted(os.listdir(path))\n","        self.path = path\n","\n","    def __len__(self):\n","        return len(self.images) // 2\n","\n","    def __getitem__(self, idx):\n","        img_path_ = self.images[idx*2]\n","\n","        img_path = self.path + '/' + img_path_[:-8] + 'crop.jpg'\n","        seg_path = self.path + '/' + img_path_[:-8] + 'mask.jpg'\n","\n","        img = plt.imread(img_path)\n","        seg = plt.imread(seg_path)\n","\n","        img = torch.tensor(img)\n","        seg = torch.tensor(seg)\n","\n","        img = img.permute(2,0,1)\n","        seg = seg.permute(2,0,1)\n","\n","        C, H, W = img.shape\n","\n","        img_seg = torch.zeros((C, H, W * 2), dtype=seg.dtype)\n","        img_seg[...,:W] = img\n","        img_seg[...,W:] = seg\n","        img_seg = color_transform(img_seg)\n","        \n","        seg = img_seg[...,W:].permute(1,2,0)\n","        \n","        N = 5\n","        \n","#         seg = torch.zeros_like(seg).fill_(255)\n","        seg = torch.floor(torch.floor((seg*(N/256)))*(256/N)).int()\n","        qnt = ((seg[...,0] + seg[...,1] * N + seg[...,2] * N * N) * N // 255).long()\n","#         print(seg.max(), qnt.max(), qnt.min())\n","        sem = torch.nn.functional.one_hot(qnt, N**3).permute(2,0,1)\n","        sem = sem.float()\n","        \n","        img = img_seg[...,:W] / 127.5 - 1\n","        seg = seg / 127.5 - 1\n","\n","        # plt.imshow(img.permute(1,2,0))\n","        # plt.show()\n","        # plt.imshow(seg.permute(1,2,0))\n","\n","        return qnt, seg.unsqueeze(0), sem.unsqueeze(0) ,img.unsqueeze(0)\n","    \n","dataset = SpaceImageSegDataset('../input/spacegan/crops_masks')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-17T21:02:18.077442Z","iopub.status.busy":"2022-08-17T21:02:18.076688Z","iopub.status.idle":"2022-08-17T21:02:18.093353Z","shell.execute_reply":"2022-08-17T21:02:18.091728Z","shell.execute_reply.started":"2022-08-17T21:02:18.077397Z"},"trusted":true},"outputs":[],"source":["qnt, seg, sem, img = dataset[1]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-08-17T14:49:23.320044Z","iopub.status.idle":"2022-08-17T14:49:23.320845Z","shell.execute_reply":"2022-08-17T14:49:23.320628Z","shell.execute_reply.started":"2022-08-17T14:49:23.320605Z"},"trusted":true},"outputs":[],"source":["N = 5\n","x = torch.tensor(255)\n","print(torch.floor((x*(N/256))))\n","torch.floor(torch.floor((x*(N/256)))*(255/N)).int()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-08-17T14:49:23.325236Z","iopub.status.idle":"2022-08-17T14:49:23.325989Z","shell.execute_reply":"2022-08-17T14:49:23.325765Z","shell.execute_reply.started":"2022-08-17T14:49:23.325742Z"},"trusted":true},"outputs":[],"source":["qnt.unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-08-17T14:49:23.327314Z","iopub.status.idle":"2022-08-17T14:49:23.328070Z","shell.execute_reply":"2022-08-17T14:49:23.327863Z","shell.execute_reply.started":"2022-08-17T14:49:23.327841Z"},"trusted":true},"outputs":[],"source":["plt.imshow(seg[0].permute(1,2,0))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-08-17T14:49:23.329416Z","iopub.status.idle":"2022-08-17T14:49:23.330444Z","shell.execute_reply":"2022-08-17T14:49:23.330229Z","shell.execute_reply.started":"2022-08-17T14:49:23.330206Z"},"trusted":true},"outputs":[],"source":["plt.imshow(qnt)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-08-17T14:49:23.333179Z","iopub.status.idle":"2022-08-17T14:49:23.342482Z","shell.execute_reply":"2022-08-17T14:49:23.342237Z","shell.execute_reply.started":"2022-08-17T14:49:23.342213Z"},"trusted":true},"outputs":[],"source":["qnt.unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-08-17T14:49:23.344004Z","iopub.status.idle":"2022-08-17T14:49:23.344849Z","shell.execute_reply":"2022-08-17T14:49:23.344494Z","shell.execute_reply.started":"2022-08-17T14:49:23.344467Z"},"trusted":true},"outputs":[],"source":["for i in range(125):\n","    plt.title(i)\n","    plt.imshow(sem[0][i].cpu(), cmap='gray')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-17T21:04:54.675126Z","iopub.status.busy":"2022-08-17T21:04:54.674736Z","iopub.status.idle":"2022-08-17T21:04:54.690580Z","shell.execute_reply":"2022-08-17T21:04:54.688943Z","shell.execute_reply.started":"2022-08-17T21:04:54.675079Z"},"trusted":true},"outputs":[],"source":["train"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
